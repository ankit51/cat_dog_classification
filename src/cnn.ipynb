{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper-parameters\n",
    "#cnn:\n",
    "num_of_layers = [1,2,3]\n",
    "num_of_filters = [32, 64, 128]\n",
    "size_of_filters = [(3,3),(4num_of_layers]\n",
    "size_of_mp = [(2,2), (3,3)]\n",
    "activation = ['relu']\n",
    "#dnn:\n",
    "num_of_dense_layers = [0,1,2]\n",
    "num_of_neurons = [32,64,128]\n",
    "activation_dense = ['relu', 'leakyrelu']\n",
    "dropout = [0.2,0.3]\n",
    "activation_output = ['sigmoid', 'softmax']\n",
    "learning_rate = [1e-4]\n",
    "validation_size = [0.1,0.2]\n",
    "batch_size = [32,64]\n",
    "loss = ['binary_crossentropy']\n",
    "optimizer = ['adam']\n",
    "metrics = ['accuracy']\n",
    "epochs = [3,9,27,81,243]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-conv-32-nodes-4-dense-1555997128\n",
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/30\n",
      "22451/22451 [==============================] - 287s 13ms/sample - loss: 2.0856 - acc: 0.6087 - val_loss: 0.5834 - val_acc: 0.7142\n",
      "Epoch 2/30\n",
      "22451/22451 [==============================] - 282s 13ms/sample - loss: 1.9949 - acc: 0.7038 - val_loss: 0.5201 - val_acc: 0.7623\n",
      "Epoch 3/30\n",
      "22451/22451 [==============================] - 278s 12ms/sample - loss: 1.9054 - acc: 0.7486 - val_loss: 0.5321 - val_acc: 0.7635\n",
      "Epoch 4/30\n",
      "22451/22451 [==============================] - 280s 12ms/sample - loss: 1.9113 - acc: 0.7481 - val_loss: 0.5215 - val_acc: 0.7647\n",
      "Epoch 5/30\n",
      "22451/22451 [==============================] - 281s 13ms/sample - loss: 1.9297 - acc: 0.7631 - val_loss: 0.8418 - val_acc: 0.6393\n",
      "Epoch 6/30\n",
      "22451/22451 [==============================] - 282s 13ms/sample - loss: 2.0002 - acc: 0.6924 - val_loss: 0.6289 - val_acc: 0.6810\n",
      "Epoch 7/30\n",
      "22451/22451 [==============================] - 281s 13ms/sample - loss: 1.9390 - acc: 0.7550 - val_loss: 0.5529 - val_acc: 0.7431\n",
      "Epoch 8/30\n",
      "22451/22451 [==============================] - 286s 13ms/sample - loss: 1.8693 - acc: 0.7952 - val_loss: 0.6401 - val_acc: 0.7455\n",
      "Epoch 9/30\n",
      "22451/22451 [==============================] - 287s 13ms/sample - loss: 1.8385 - acc: 0.8291 - val_loss: 0.6721 - val_acc: 0.7431\n",
      "Epoch 10/30\n",
      "22451/22451 [==============================] - 288s 13ms/sample - loss: 1.7345 - acc: 0.8607 - val_loss: 0.7706 - val_acc: 0.7455\n",
      "Epoch 11/30\n",
      "22451/22451 [==============================] - 284s 13ms/sample - loss: 1.7997 - acc: 0.8584 - val_loss: 0.8423 - val_acc: 0.7359\n",
      "Epoch 12/30\n",
      "22451/22451 [==============================] - 282s 13ms/sample - loss: 1.7228 - acc: 0.8691 - val_loss: 0.7445 - val_acc: 0.7431\n",
      "Epoch 13/30\n",
      "22451/22451 [==============================] - 281s 13ms/sample - loss: 1.6738 - acc: 0.8809 - val_loss: 1.0049 - val_acc: 0.7427\n",
      "Epoch 14/30\n",
      "22451/22451 [==============================] - 285s 13ms/sample - loss: 1.7024 - acc: 0.8830 - val_loss: 1.0141 - val_acc: 0.7335\n",
      "Epoch 15/30\n",
      "22451/22451 [==============================] - 281s 13ms/sample - loss: 1.7846 - acc: 0.8510 - val_loss: 0.9789 - val_acc: 0.7375\n",
      "Epoch 16/30\n",
      "22451/22451 [==============================] - 283s 13ms/sample - loss: 1.6316 - acc: 0.8934 - val_loss: 1.0470 - val_acc: 0.7347\n",
      "Epoch 17/30\n",
      "22451/22451 [==============================] - 283s 13ms/sample - loss: 1.6548 - acc: 0.8923 - val_loss: 1.0384 - val_acc: 0.7307\n",
      "Epoch 18/30\n",
      "22451/22451 [==============================] - 288s 13ms/sample - loss: 1.7102 - acc: 0.8866 - val_loss: 1.3895 - val_acc: 0.7190\n",
      "Epoch 19/30\n",
      "22451/22451 [==============================] - 288s 13ms/sample - loss: 1.6457 - acc: 0.8939 - val_loss: 1.2898 - val_acc: 0.7110\n",
      "Epoch 20/30\n",
      "22451/22451 [==============================] - 284s 13ms/sample - loss: 1.6824 - acc: 0.8724 - val_loss: 1.0250 - val_acc: 0.7311\n",
      "Epoch 21/30\n",
      "22451/22451 [==============================] - 281s 13ms/sample - loss: 1.6848 - acc: 0.8915 - val_loss: 1.1593 - val_acc: 0.7403\n",
      "Epoch 22/30\n",
      "22451/22451 [==============================] - 284s 13ms/sample - loss: 1.6641 - acc: 0.8911 - val_loss: 1.2246 - val_acc: 0.7210\n",
      "Epoch 23/30\n",
      "22451/22451 [==============================] - 284s 13ms/sample - loss: 1.6008 - acc: 0.8975 - val_loss: 1.3660 - val_acc: 0.7303\n",
      "Epoch 24/30\n",
      "22451/22451 [==============================] - 284s 13ms/sample - loss: 1.6376 - acc: 0.8860 - val_loss: 1.2433 - val_acc: 0.7423\n",
      "Epoch 25/30\n",
      "22451/22451 [==============================] - 281s 13ms/sample - loss: 1.5972 - acc: 0.8988 - val_loss: 1.5596 - val_acc: 0.7251\n",
      "Epoch 26/30\n",
      "22451/22451 [==============================] - 281s 13ms/sample - loss: 1.6718 - acc: 0.8937 - val_loss: 1.4364 - val_acc: 0.7399\n",
      "Epoch 27/30\n",
      "22451/22451 [==============================] - 281s 13ms/sample - loss: 1.6424 - acc: 0.8944 - val_loss: 1.6682 - val_acc: 0.7158\n",
      "Epoch 28/30\n",
      "22451/22451 [==============================] - 283s 13ms/sample - loss: 1.7437 - acc: 0.8780 - val_loss: 1.1412 - val_acc: 0.7114\n",
      "Epoch 29/30\n",
      "22451/22451 [==============================] - 282s 13ms/sample - loss: 1.6344 - acc: 0.8932 - val_loss: 1.2624 - val_acc: 0.7343\n",
      "Epoch 30/30\n",
      "22451/22451 [==============================] - 281s 13ms/sample - loss: 1.5974 - acc: 0.8981 - val_loss: 1.3488 - val_acc: 0.7335\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "\n",
    "def gen_list(p=0, x=1, n=3):\n",
    "    return [x*(2**k)+p for k in range(n)]\n",
    "\n",
    "dense_layers = gen_list()\n",
    "layer_sizes = gen_list(0, 32)\n",
    "conv_layers = [2]\n",
    "\n",
    "dense_layers = [4]\n",
    "layer_sizes = [32]\n",
    "conv_layers = [2]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            model.fit(X, y,\n",
    "                      batch_size=32,\n",
    "                      epochs=30,\n",
    "                      validation_split=0.1,\n",
    "                      callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
